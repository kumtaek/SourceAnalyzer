# 개선계획서 구체적 구현 답변서 (Implementation Guide)

## 문서 정보
- **작성일**: 2025년 9월 18일
- **답변자**: Gemini (AI Assistant)
- **대상 문서**: `docs/기능개선/Q_20250918_개선계획서_질의2.md`
- **답변 목적**: 제기된 모든 질의에 대한 구체적인 구현 로직과 알고리즘을 제공하여, 개발자가 즉시 코딩에 착수할 수 있도록 지원

---

## 🎯 구체적 구현 로직 답변

### 1. **MyBatis 동적 SQL - 구체적 알고리즘 설계**

#### 1-1. 조합 생성 알고리즘 상세 구현

**질의 1-1-1: 조합 생성 순서와 우선순위**

-   **생성 순서**: **DFS(깊이 우선 탐색)** 기반의 재귀적 순회로 XML 노드를 탐색하며 조합을 생성합니다. 이 방식이 중첩 구조를 자연스럽게 처리하기에 용이합니다.
-   **우선순위**: 최대 조합 수(예: 32개)를 초과할 경우, **모든 조합 생성을 즉시 중단**하고, 앞서 답변드린 **대표 경로(Representative Path) 분석**으로 전환합니다. 32개 조합 중 일부를 선택하는 것이 아니라, 분석 전략 자체를 변경하여 성능을 보장합니다.

    1.  **Inclusive Path (가장 복잡한 경로)**: 모든 `<if>`를 `true`로, `<choose>`에서는 첫 번째 `<when>`을 선택.
    2.  **Base Path (가장 단순한 경로)**: 모든 `<if>`를 `false`로, `<choose>`에서는 `<otherwise>`를 선택.

**질의 1-1-2: 데이터 구조 설계**

제안하신 `SqlPath` 클래스는 좋은 출발점입니다. 이를 좀 더 구체화하고 단순화하여, **경로별 SQL 텍스트 자체에만 집중**하는 방식으로 설계하겠습니다. 분석(테이블 추출 등)은 모든 경로 생성이 끝난 후 일괄적으로 수행하는 것이 효율적입니다.

```python
# 최종적으로 사용할 데이터 구조는 단순한 문자열 리스트입니다.
# List[str]: 각 문자열이 하나의 완전한 SQL 경로를 나타냄

# 재귀 함수 내에서 사용할 상태 객체 (필요 시)
from dataclasses import dataclass, field
from typing import List

@dataclass
class TraversalState:
    """ 재귀 탐색 중 각 경로의 상태를 관리하는 데이터 클래스 """
    sql: str = ""
    # 추후 조건절 변수 등 추가 확장 가능
```

#### 1-2. 중첩 구조 처리 - 상태 관리 로직

**질의 1-2-1 & 1-2-2: 재귀 상태 관리 및 메모리 최적화**

핵심은 **새로운 리스트를 반환하는(Return new list)** 재귀 함수를 설계하여, 각 재귀 단계가 이전 단계의 상태에 영향을 주지 않도록 하는 것입니다. 이를 통해 상태 복제 문제를 단순화하고 메모리 관리를 용이하게 합니다.

**[의사 코드 / Python 상세 로직]**

```python
# D:\Analyzer\CreateMetaDb\parser\xml_parser.py 내 구현 제안

MAX_COMBINATIONS = 32
MAX_RECURSION_DEPTH = 15

class MybatisParser:
    # ...

    def _generate_sql_paths(self, node: ET.Element, depth: int = 0) -> List[str]:
        """
        XML 노드를 재귀적으로 탐색하여 모든 가능한 SQL 경로 리스트를 반환한다.
        """
        if depth > MAX_RECURSION_DEPTH:
            return [""] # 재귀 깊이 초과 시 빈 경로 반환

        # 현재 노드의 머리(text) 부분으로 초기 경로 설정
        # 자식 노드가 없는 텍스트만 있는 노드를 위한 처리
        initial_text = node.text.strip() if node.text else ""
        paths = [initial_text]

        for child_node in node:
            # 1. 자식 노드를 재귀적으로 탐색하여 하위 경로 생성
            child_paths = self._generate_sql_paths(child_node, depth + 1)

            # 2. 현재 경로와 하위 경로를 조합
            combined_paths = []
            if child_node.tag == 'if':
                # <if>: 하위 경로를 포함하는 경우와 포함하지 않는 경우로 분기
                for p in paths:
                    # 포함하지 않는 경로 (기존 경로 유지)
                    combined_paths.append(p)
                    # 포함하는 경로
                    for cp in child_paths:
                        combined_paths.append(f"{p} {cp}")
            
            elif child_node.tag == 'choose':
                # <choose>: 하위 경로들(when/otherwise)은 상호 배타적 확장
                for p in paths:
                    for cp in child_paths:
                        combined_paths.append(f"{p} {cp}")
            
            else: # 일반 텍스트, 다른 태그 등
                # 일반: 현재 경로에 하위 경로를 이어붙임
                for p in paths:
                    for cp in child_paths:
                        combined_paths.append(f"{p} {cp}")
            
            paths = combined_paths

            # 3. 최대 조합 수 체크
            if len(paths) > MAX_COMBINATIONS:
                # 대표 경로 분석으로 전환 (실제 구현에서는 예외를 발생시켜 상위에서 처리)
                raise ValueError("Combination explosion detected")

            # 4. 자식 노드의 꼬리(tail) 텍스트 추가
            if child_node.tail and child_node.tail.strip():
                tail_text = child_node.tail.strip()
                paths = [f"{p} {tail_text}" for p in paths]
        
        # <choose>의 경우, 자식(when/otherwise)들이 병렬적이므로, 그 결과를 합쳐서 반환
        if node.tag == 'choose':
            final_paths = []
            for child_node in node:
                # 각 자식(when/otherwise)은 독립적인 경로를 생성
                final_paths.extend(self._generate_sql_paths(child_node, depth + 1))
            return final_paths

        return paths

    def parse_sql_node(self, node: ET.Element):
        try:
            sql_paths = self._generate_sql_paths(node)
        except ValueError: # 조합 폭발 발생 시
            # 대표 경로 분석 로직 호출
            sql_paths = self._get_representative_paths(node)
        
        # 최종적으로 생성된 모든 SQL 경로를 분석...
```

### 2. **SqlFragmentCache 구체적 구현**

#### 2-1. 캐시 구조와 생명주기

**질의 2-1-1: 캐시 데이터 구조**

-   **`fragments` 저장 값**: 파싱된 **`ET.Element` 객체**를 저장합니다. 문자열로 저장 후 매번 재파싱하는 비용을 줄일 수 있습니다.
-   **`dependency_graph`**: **캐시 로드 시에만 사용**하여 순환 참조를 탐지하고, 메모리 절약을 위해 **탐지 후에는 파기**합니다. 런타임 `<include>` 해석 시에는 필요 없습니다.

**질의 2-1-2: 캐시 무효화 전략**

-   현재 시스템은 단일 실행(Single-run) 배치 프로세스이므로, 복잡한 무효화 전략은 불필요합니다. **분석 시작 시 항상 캐시를 새로 로드**하는 것이 가장 간단하고 확실한 방법입니다. (프로세스 실행 동안만 유지되는 캐시)

#### 2-2. 순환 참조 탐지 구체적 구현

**질의 2-2-1: 탐지 시점과 처리**

-   **탐지 시점**: **캐시 사용 시(Runtime)**에 탐지하는 것이 가장 효율적입니다.
-   **처리 로직**: 제안하신 대로, **경고 로그를 남기고 빈 문자열을 반환**하는 것이 가장 안정적인 처리 방식입니다.

**[의사 코드 / Python 상세 로직]**

```python
# D:\Analyzer\CreateMetaDb\parser\xml_parser.py 내 구현 제안

class MybatisParser:
    def __init__(self, sql_parser, fragment_cache: SqlFragmentCache):
        self.sql_parser = sql_parser
        self.fragment_cache = fragment_cache

    def _resolve_includes(self, node: ET.Element, call_stack: Set[str]) -> str:
        """ <include> 태그를 재귀적으로 해석. call_stack으로 순환 참조 감지 """
        # ... (텍스트, 자식 노드 처리 로직) ...
        
        for child in node:
            if child.tag == 'include':
                refid = child.attrib.get('refid')
                if refid in call_stack:
                    # 순환 참조 발견!
                    logger.warning(f"Circular include detected for refid='{refid}'. Skipping.")
                    # 여기서 재귀를 중단하고 빈 문자열로 처리
                    continue 
                
                fragment_node = self.fragment_cache.get_fragment_node(refid)
                if fragment_node:
                    # 새로운 호출 스택으로 재귀 호출
                    new_stack = call_stack.copy()
                    new_stack.add(refid)
                    sql_text += self._resolve_includes(fragment_node, new_stack)
            # ...
```

### 3. **Java AST 분석 - 구체적 파싱 로직**

#### 3-1. 변수 추적 구체적 구현

**질의 3-1-1: 지원 범위 명확화**

-   **Case 1 (`sql += "..."`)**: ✅ **지원** (가장 기본적인 패턴)
-   **Case 2 (`sql += variable`)**: ❌ **미지원** (변수-변수 간의 결합은 추적 복잡도를 급격히 높이므로 MVP에서 제외)
-   **Case 3 (`sql = "... " + variable`)**: ❌ **미지원** (Case 2와 동일)

**결론**: **추적 대상 변수**와 **문자열 리터럴(Literal)** 간의 `+`, `+=` 연산만 지원 범위로 한정합니다.

**질의 3-1-2: AST 노드 처리 로직**

```python
# D:\Analyzer\CreateMetaDb\parser\java_parser.py 내 구현 제안

def analyze_method_body_for_sql(self, method_node) -> List[str]:
    tracked_vars = {}  # Dict[str, str]: 변수명 -> 추적 중인 SQL 문자열

    if not method_node.body:
        return []

    for stmt in method_node.body:
        # Case 1: 변수 선언 (String sql = "...")
        if isinstance(stmt, javalang.tree.LocalVariableDeclaration) and stmt.type.name == 'String':
            for declarator in stmt.declarators:
                if isinstance(declarator.initializer, javalang.tree.Literal):
                    var_name = declarator.name
                    tracked_vars[var_name] = declarator.initializer.value.strip('"')

        # Case 2: 변수 할당 (sql = ..., sql += ...)
        elif isinstance(stmt, javalang.tree.ExpressionStatement) and isinstance(stmt.expression, javalang.tree.Assignment):
            assignment = stmt.expression
            # 할당받는 변수 이름 추출 (단순 MemberReference만 지원)
            if not isinstance(assignment.expressionl, javalang.tree.MemberReference): continue
            var_name = assignment.expressionl.member
            
            if var_name not in tracked_vars: continue

            # Case 2-1: sql += "..."
            if assignment.type == '+=' and isinstance(assignment.value, javalang.tree.Literal):
                tracked_vars[var_name] += " " + assignment.value.value.strip('"')
            
            # Case 2-2: sql = sql + "..."
            elif assignment.type == '=' and isinstance(assignment.value, javalang.tree.BinaryOperation) and assignment.value.operator == '+':
                bin_op = assignment.value
                # 좌변이 추적 중인 변수이고, 우변이 리터럴일 때
                if isinstance(bin_op.operandl, javalang.tree.MemberReference) and bin_op.operandl.member == var_name and isinstance(bin_op.operandr, javalang.tree.Literal):
                    tracked_vars[var_name] += " " + bin_op.operandr.value.strip('"')
    
    return [sql for sql in tracked_vars.values() if self._is_likely_sql(sql)]
```

#### 3-2. SQL 패턴 인식 로직

**질의 3-2-1: 인식 정확도 개선**

-   **방식 3 (실제 SQL 파서로 검증)**은 가장 정확하지만, 모든 문자열 조각에 대해 파서를 실행하는 것은 성능 부하가 너무 큽니다.
-   **방식 1 (키워드 조합 체크)**이 성능과 정확도의 가장 좋은 절충안입니다.

**[개선된 최종 로직]**

```python
def _is_likely_sql(self, text: str) -> bool:
    text_upper = text.upper().strip()
    
    # 너무 짧거나 키워드가 없으면 조기 탈락
    if len(text_upper) < 10 or not any(k in text_upper for k in ['SELECT', 'INSERT', 'UPDATE', 'DELETE']):
        return False

    # 키워드 조합으로 신뢰도 높은 패턴 확인
    has_select_from = 'SELECT' in text_upper and 'FROM' in text_upper
    has_insert_into = 'INSERT' in text_upper and 'INTO' in text_upper
    has_update_set = 'UPDATE' in text_upper and 'SET' in text_upper
    has_delete_from = 'DELETE' in text_upper and 'FROM' in text_upper
    
    return has_select_from or has_insert_into or has_update_set or has_delete_from
```

### 4. **통합 및 에러 처리 - 구체적 플로우**

**질의 4-1-1: 통합 지점 선택**

-   **통합 지점**: `MybatisParser` 클래스 내에 `_dynamic_parse_node`와 같은 새로운 private 메서드를 만들고, 기존의 SQL 노드를 처리하는 최상위 public 메서드(예: `parse_sql_mapper` 또는 `parse_sql_node`)의 시작 부분에서 이를 호출합니다.
-   **실행 순서**: 1) `<include>` 해석 → 2) 동적 SQL 경로 생성 → 3) 각 경로별 SQL 파싱.
-   **결과 병합**: 새로운 동적 분석 방식은 기존 방식을 완전히 대체합니다. 따라서 결과를 병합할 필요 없이, 새 방식의 결과를 최종 결과로 사용합니다. 실패 시에만 기존 방식으로 Fallback합니다.

**질의 4-2-1 & 4-2-2: Fallback 메커니즘**

-   **실패 판단 기준**: `_dynamic_parse_node` 내부에서 발생하는 모든 **`Exception`** (e.g., `ValueError` for combination explosion, `ET.ParseError`, `RecursionError` 등)을 "실패"로 간주합니다.
-   **결과 병합 전략**: **새 방식 우선(New method first)**. 새 방식이 성공하면 그 결과만 사용합니다. 새 방식이 실패(Exception 발생)해야만 기존 방식을 호출하고 그 결과를 사용합니다. 두 방식의 결과를 합치지는 않습니다.

### 5. **성능 측정 및 검증 구체화**

**질의 5-1-1: 측정 지표 구체화**

-   제안하신 지표 모두 훌륭합니다. 추가로 **'동적 SQL 경로 생성 수'**, **'Fallback 발생 횟수'**를 측정하면 기능의 동작을 더 잘 이해할 수 있습니다.

**질의 5-2-1: 테스트 케이스 예상 결과**

-   각 테스트 케이스(`.xml`, `.java`)에 대해, `.expected.json` 파일을 쌍으로 만듭니다. 이 JSON 파일에는 해당 테스트 케이스를 분석했을 때 나와야 하는 **테이블 목록, 컬럼 목록, 조인 관계 목록**을 명시합니다. 테스트 실행 시, 실제 분석 결과와 이 `.expected.json` 파일을 비교하여 일치 여부를 검증합니다.

### 🔧 구현 우선순위 재확인

제안해주신 **Phase 1-A, 1-B, 2**의 단계별 구현 계획은 매우 합리적이고 실현 가능합니다. 이 순서대로 진행하는 것을 적극 권장합니다.

---

**최종 결론**: 이 답변서에 기술된 데이터 구조, 알고리즘, 예외 처리 방안을 따르면, 개발자는 제안된 기능 개선 사항을 체계적이고 안정적으로 구현할 수 있을 것입니다.
