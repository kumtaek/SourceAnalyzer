# 개선계획서 User Rules 반영 구체적 구현 질의서 3

## 문서 정보
- **작성일**: 2025년 9월 18일
- **질의자**: AI Assistant (개발자 관점)
- **대상 문서**: `docs/기능개선/A_20250918_개선계획서_답변2.md`
- **질의 목적**: User Rules 준수하여 기존 시스템 영향 없는 안전한 구현 방안

---

## 핵심 목표 재확인

> **최우선 목표**: 누락없이 연결구조를 도출해 내는 것
> **쿼리 처리 범위**: INSERT, UPDATE, DELETE, SELECT, MERGE - 관련 테이블과 조인관계만 추출
> **목적**: 자바파일이나 쿼리 전체를 완벽하게 파싱하는게 아님. 목적달성에 최선을 고려

---

## User Rules 준수 구체적 질의

### 1. **기존 로직 영향 없는 안전한 통합**

#### 1-1. 현재 xml_parser.py 구조 분석
현재 `MybatisParser` 클래스의 기존 메서드들과 충돌 없이 통합하려면:

```python
# 현재 xml_parser.py 구조 (추정)
class MybatisParser:
    def __init__(self, dom_rules: Dict[str, Any]):
        # 기존 초기화 로직
        
    def parse_sql_mapper(self, xml_root: ET.Element) -> List[Dict[str, str]]:
        # 기존 메인 파싱 로직
        
    def _process_node(self, node: ET.Element, context: Dict[str, str]) -> str:
        # 기존 노드 처리 로직
```

**질의 1-1-1**: **안전한 확장 방식**
- 답변2에서 제안한 `_generate_sql_paths()` 메서드를 어느 위치에 추가할 것인가?
- 기존 `parse_sql_mapper()` 메서드를 수정할 것인가, 아니면 새로운 메서드를 만들어 호출할 것인가?
- 기존 DOM 규칙(`mybatis_dom_rules.yaml`) 설정과 충돌하지 않는 방법은?

**질의 1-1-2**: **Fallback 메커니즘 구체화**
```python
def enhanced_parse_sql_node(self, node: ET.Element) -> Dict[str, Any]:
    try:
        # 새로운 동적 분석 시도
        result = self._dynamic_sql_analysis(node)
        return result
    except Exception as e:
        # 기존 방식으로 Fallback
        logger.warning(f"동적 분석 실패, 기존 방식으로 처리: {e}")
        return self._legacy_parse_sql_node(node)  # 기존 로직 호출
```

이때 `_legacy_parse_sql_node()`는 기존의 어떤 메서드를 호출해야 하는가?

#### 1-2. 공통함수 활용 및 중복 방지

**질의 1-2-1**: **PathUtils 활용**
답변2의 `SqlFragmentCache`에서 XML 파일 스캔 시:
```python
# 답변2에서 제안된 코드
xml_files = glob(os.path.join(project_path, '**', '*.xml'), recursive=True)
```

User Rules에 따라 공통함수를 사용해야 하므로:
```python
# PathUtils 활용 방식
from util.path_utils import PathUtils
path_utils = PathUtils()
xml_files = path_utils.find_files_by_pattern(project_path, "*.xml", recursive=True)
```

하지만 `target_source_config.yaml`의 `include_patterns`와 `exclude_patterns`도 고려해야 하는데, 어떻게 통합할 것인가?

**질의 1-2-2**: **중복 공통함수 방지**
현재 util 폴더에 있는 기능들과 중복되지 않도록:
- `SqlFragmentCache` 클래스가 기존 `DatabaseCache`와 역할이 겹치지 않는가?
- XML 파싱 관련 공통 기능이 이미 존재하는가?
- 에러 처리를 위한 `handle_error()` 함수 사용법은?

### 2. **Exception 처리 - handle_error() 적용**

#### 2-1. 모든 Exception을 handle_error()로 처리
User Rules: "exception발생시 handle_error()로 로그남기고 Exit!"

답변2의 코드에서 다음 부분들을 수정해야 함:

```python
# 답변2 원본
try:
    sql_paths = self._generate_sql_paths(node)
except ValueError: # 조합 폭발 발생 시
    # 대표 경로 분석 로직 호출
    sql_paths = self._get_representative_paths(node)
```

**질의 2-1-1**: **handle_error() 적용 범위**
- 조합 폭발(`ValueError`)도 handle_error()로 처리해야 하는가?
- 아니면 예상 가능한 상황이므로 warning 후 계속 진행해도 되는가?
- has_error='Y' 파싱 에러와 시스템 에러를 어떻게 구분할 것인가?

```python
# 수정 필요한 코드
try:
    sql_paths = self._generate_sql_paths(node)
except ValueError as e:
    # 이것을 handle_error()로 처리할 것인가?
    handle_error(e, "SQL 조합 폭발 발생")  # 이렇게 하면 exit()됨
    # 아니면 warning 후 fallback?
    logger.warning(f"조합 폭발로 대표 경로 분석으로 전환: {e}")
    sql_paths = self._get_representative_paths(node)
```

#### 2-2. Java AST 파싱 에러 처리
```python
# 답변2의 Java 파싱 코드
try:
    tree = javalang.parse.parse(content)
except javalang.tokenizer.LexerError:
    pass # 파싱 실패는 무시
```

**질의 2-2-1**: **Java 파싱 실패 처리 방침**
- `javalang.tokenizer.LexerError`는 파싱 에러이므로 has_error='Y' 처리?
- 아니면 시스템 에러로 간주하여 handle_error() 처리?
- Java 파일 전체 분석을 포기할 것인가, 해당 메서드만 스킵할 것인가?

### 3. **target_source_config.yaml 활용 - 하드코딩 제거**

#### 3-1. 분석 대상 파일 필터링
User Rules: "SampleSrc 하위 폴더,파일에 특화되게 하드코딩하면 안됨"

답변2의 `SqlFragmentCache.load_all_fragments()`에서:
```python
# 답변2 원본 (하드코딩)
xml_files = glob(os.path.join(project_path, '**', '*.xml'), recursive=True)
```

**질의 3-1-1**: **설정 파일 기반 동적 필터링**
`target_source_config.yaml`의 다음 설정들을 어떻게 활용할 것인가?
- `include_patterns: ["**/*.xml"]`
- `exclude_directories: ["**/target/**", "**/build/**"]`
- `file_type_settings.xml.enabled: true`
- `file_type_settings.xml.max_lines: 5000`

```python
# 개선된 방식 (설정 파일 기반)
def load_all_fragments(self, project_path: str):
    # target_source_config.yaml 로드
    config = self._load_target_source_config()
    
    # 설정에 따른 XML 파일 필터링
    xml_files = self._find_xml_files_by_config(project_path, config)
    
    for file_path in xml_files:
        # 파일 크기, 라인 수 체크
        if not self._is_valid_xml_file(file_path, config):
            continue
        # 파싱 진행...
```

#### 3-2. 크로스 플랫폼 대응
User Rules: "Windows, RHEL 크로스플랫폼 대응"

**질의 3-2-1**: **경로 처리 방식**
- 모든 경로 처리에 `PathUtils`를 사용해야 하는가?
- `os.path.join()` vs `pathlib.Path` vs `PathUtils.join_path()` 중 어떤 것을 사용?
- 절대/상대 경로 변환은 `PathUtils.normalize_path()` 사용?

### 4. **성능 최적화 - 목적 달성 중심**

#### 4-1. 테이블/조인 관계만 추출하는 최적화
User Rules: "쿼리는 관련 테이블과 조인관계만 추출하면됨"

답변2에서 제안한 복잡한 SQL 경로 생성이 과도할 수 있음:

**질의 4-1-1**: **간소화된 접근법**
복잡한 동적 SQL 조합 대신, 다음과 같은 단순한 방식은?
```python
def extract_tables_from_dynamic_sql(self, node: ET.Element) -> Set[str]:
    """동적 SQL에서 테이블명만 추출 (조합 생성 없이)"""
    tables = set()
    
    # 모든 텍스트 노드에서 테이블 패턴 추출
    all_text = self._get_all_text_content(node)  # <if> 내부 포함
    
    # FROM, JOIN 패턴으로 테이블명 추출
    table_patterns = [
        r'FROM\s+([a-zA-Z_][a-zA-Z0-9_]*)',
        r'JOIN\s+([a-zA-Z_][a-zA-Z0-9_]*)',
        r'UPDATE\s+([a-zA-Z_][a-zA-Z0-9_]*)',
        r'INSERT\s+INTO\s+([a-zA-Z_][a-zA-Z0-9_]*)'
    ]
    
    for pattern in table_patterns:
        matches = re.findall(pattern, all_text, re.IGNORECASE)
        tables.update(matches)
    
    return tables
```

이 방식이 목적 달성에 더 적합하지 않은가?

#### 4-2. Java 파싱 범위 최소화
**질의 4-2-1**: **SQL 패턴 인식 단순화**
복잡한 AST 분석 대신:
```python
def extract_sql_from_java_simple(self, java_content: str) -> List[str]:
    """Java 코드에서 SQL 문자열 패턴 추출 (단순 정규식)"""
    sql_patterns = [
        r'"(SELECT\s+.*?FROM\s+\w+.*?)"',
        r'"(INSERT\s+INTO\s+\w+.*?)"',
        r'"(UPDATE\s+\w+\s+SET.*?)"',
        r'"(DELETE\s+FROM\s+\w+.*?)"'
    ]
    
    found_sqls = []
    for pattern in sql_patterns:
        matches = re.findall(pattern, java_content, re.IGNORECASE | re.DOTALL)
        found_sqls.extend(matches)
    
    return found_sqls
```

이런 단순한 방식으로도 목적 달성이 가능하지 않은가?

### 5. **기존 단계 유지 - 통합 방식**

#### 5-1. 현재 처리 단계와의 연동
User Rules: "기본 틀인 각 단계는 유지하는거지?"

현재 단계: 1단계(파일스캔) → 2단계(DB구조) → 3단계(XML분석) → 4단계(Java분석) → ...

**질의 5-1-1**: **3단계 XML 분석 확장**
- 새로운 동적 SQL 분석을 3단계에 통합할 것인가?
- 아니면 별도 단계(예: 3.5단계)로 분리할 것인가?
- 기존 3단계 완료 후 추가 처리? 아니면 3단계 내부에서 동시 처리?

**질의 5-1-2**: **4단계 Java 분석 확장**
- Java SQL 추출을 4단계에 통합할 것인가?
- 기존 클래스/메서드 추출 로직과 분리해야 하는가?
- 추출된 Java SQL을 어느 단계에서 분석할 것인가? (3단계? 4단계?)

### 6. **구체적 구현 순서 - Phase별 세부 계획**

#### 6-1. Phase 1-A 구체적 작업 범위
**1주차 목표를 다시 구체화**:

**질의 6-1-1**: **SqlFragmentCache 구현 범위**
- 같은 파일 내 `<include>` 해석만? 크로스 파일도?
- 순환 참조 탐지는 Phase 1-A에 포함? Phase 1-B로 연기?
- 성능 테스트 기준: XML 파일 몇 개까지 처리 가능해야 하는가?

**질의 6-1-2**: **단순 `<if>` 태그 처리 범위**
- 중첩 없는 `<if>` 태그 최대 몇 개까지?
- `<choose>` 태그는 Phase 1-A에서 제외?
- 테스트 케이스: 어떤 XML 파일로 검증할 것인가?

#### 6-2. 검증 및 테스트 전략
**질의 6-2-1**: **기존 시스템 영향 없음 검증**
- 개선 전후 sampleSrc 분석 결과 비교 방법?
- 기존 127개 SQL 컴포넌트 수가 변경되어도 되는가?
- 새로운 기능으로 추가 발견된 테이블/관계는 어떻게 검증?

**질의 6-2-2**: **단위 테스트 구체화**
```
test_cases/
├── phase1a/
│   ├── simple_if.xml           # <if> 태그 1개
│   ├── multiple_if.xml         # <if> 태그 3개
│   ├── same_file_include.xml   # 같은 파일 <include>
│   └── expected_results.json   # 예상 결과
```

각 테스트 케이스의 예상 결과를 어떻게 정의할 것인가?

---

## 최종 확인 질의

**질의 A**: User Rules를 모두 준수하면서도 답변2의 기술적 방향성을 유지할 수 있는가?

**질의 B**: 목적 달성(테이블/조인 관계 추출)에 집중하여 구현 복잡도를 줄일 수 있는 대안이 있는가?

**질의 C**: 기존 시스템에 전혀 영향 없이 새 기능을 추가하는 안전한 방법은 무엇인가?

---

**요청사항**: 위 모든 질의에 대해 User Rules를 완전히 준수하는 구체적 답변을 받아야 실제 개발 착수가 가능합니다.
