<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" 
    "http://mybatis.org/dtd/mybatis-3-mapper.dtd">

<!--
  복잡한 기업급 쿼리 샘플 - Java 코드와 동일한 복잡도
  Oracle 전용 쿼리들로 구성
-->
<mapper namespace="com.example.mapper.ComplexEnterpriseMapper">

    <!-- 
    복잡한 금융 정산 쿼리 - 실제 기업에서 사용할 법한 복잡도
    다중 CTE, 복잡한 JOIN, 서브쿼리, 윈도우 함수 등 모든 요소 포함
    -->
    <select id="executeFinancialReconciliation" parameterType="map" resultType="map">
        WITH daily_transactions AS (
            SELECT 
                t.transaction_date,
                t.user_id,
                t.product_id,
                t.order_id,
                SUM(CASE WHEN t.transaction_type = 'PURCHASE' THEN t.amount ELSE 0 END) as purchase_amount,
                SUM(CASE WHEN t.transaction_type = 'REFUND' THEN t.amount ELSE 0 END) as refund_amount,
                COUNT(DISTINCT t.payment_method) as payment_method_count,
                COUNT(DISTINCT t.currency_code) as currency_diversity
            FROM transactions_${environment}_${year} t
            INNER JOIN users_${environment} u ON t.user_id = u.user_id
            INNER JOIN products_${environment} p ON t.product_id = p.product_id
            INNER JOIN orders_${environment} o ON t.order_id = o.order_id
            LEFT JOIN user_tiers_${environment} ut ON u.user_id = ut.user_id
            WHERE t.transaction_date BETWEEN TO_DATE(#{dateFrom}, 'YYYY-MM-DD') 
                                        AND TO_DATE(#{dateTo}, 'YYYY-MM-DD')
            AND t.status IN ('COMPLETED', 'SETTLED', 'VERIFIED')
            AND u.account_status = 'VERIFIED'
            AND u.risk_level &lt;= #{maxRiskLevel}
            AND o.fraud_check_status = 'PASSED'
            GROUP BY t.transaction_date, t.user_id, t.product_id, t.order_id
        ),
        settlement_calculation AS (
            SELECT 
                dt.transaction_date,
                dt.user_id,
                SUM(dt.purchase_amount) as daily_revenue,
                SUM(dt.refund_amount) as daily_refunds,
                SUM(dt.purchase_amount - dt.refund_amount) as net_revenue,
                COUNT(DISTINCT dt.user_id) as unique_customers,
                AVG(dt.purchase_amount) as avg_transaction_amount,
                STDDEV(dt.purchase_amount) as revenue_volatility,
                ROW_NUMBER() OVER (PARTITION BY dt.transaction_date ORDER BY SUM(dt.purchase_amount) DESC) as daily_rank
            FROM daily_transactions dt
            INNER JOIN user_tiers_${environment} ut ON dt.user_id = ut.user_id
            INNER JOIN user_kyc_${environment} kyc ON dt.user_id = kyc.user_id
            WHERE ut.tier_level IN ('GOLD', 'PLATINUM', 'DIAMOND')
            AND kyc.verification_status = 'COMPLETED'
            AND kyc.risk_score &lt; #{maxRiskScore}
            GROUP BY dt.transaction_date, dt.user_id
        ),
        fee_calculation AS (
            SELECT 
                sc.transaction_date,
                sc.user_id,
                sc.net_revenue,
                CASE 
                    WHEN sc.net_revenue >= 1000000 THEN sc.net_revenue * 0.025  -- VIP 2.5%
                    WHEN sc.net_revenue >= 500000 THEN sc.net_revenue * 0.030   -- Premium 3.0%
                    WHEN sc.net_revenue >= 100000 THEN sc.net_revenue * 0.035   -- Standard 3.5%
                    ELSE sc.net_revenue * 0.040  -- Basic 4.0%
                END as platform_fee,
                CASE 
                    WHEN EXISTS (
                        SELECT 1 FROM tax_exemptions_${environment} te 
                        WHERE te.user_id = sc.user_id 
                        AND te.exemption_type = 'CORPORATE'
                        AND te.valid_until >= SYSDATE
                    ) THEN 0
                    ELSE sc.net_revenue * 0.10  -- 10% 세금
                END as tax_amount
            FROM settlement_calculation sc
        )
        SELECT 
            fc.transaction_date,
            fc.user_id,
            u.username,
            u.company_name,
            fc.net_revenue,
            fc.platform_fee,
            fc.tax_amount,
            ROUND(fc.net_revenue - fc.platform_fee - fc.tax_amount, 2) as final_settlement,
            CASE 
                WHEN fc.net_revenue >= 1000000 THEN 'VIP_SETTLEMENT'
                WHEN fc.net_revenue >= 500000 THEN 'PREMIUM_SETTLEMENT'
                ELSE 'STANDARD_SETTLEMENT'
            END as settlement_tier,
            (SELECT COUNT(*) FROM disputes_${environment} d 
             WHERE d.user_id = fc.user_id 
             AND d.dispute_date >= ADD_MONTHS(SYSDATE, -6)
             AND d.status = 'RESOLVED') as recent_disputes_count
        FROM fee_calculation fc
        INNER JOIN users_${environment} u ON fc.user_id = u.user_id
        LEFT JOIN user_business_info_${environment} ubi ON u.user_id = ubi.user_id
        WHERE fc.net_revenue > #{minSettlementAmount}
        ORDER BY fc.net_revenue DESC, fc.transaction_date DESC
    </select>

    <!-- 
    복잡한 고객 세분화 분석 - 머신러닝 스타일의 고급 분석 쿼리
    다중 CTE, 윈도우 함수, 복잡한 CASE 문, 통계 함수 등
    -->
    <select id="executeCustomerSegmentationAnalysis" parameterType="map" resultType="map">
        WITH customer_behavior_metrics AS (
            SELECT 
                u.user_id,
                u.user_type,
                u.registration_date,
                COUNT(DISTINCT o.order_id) as order_frequency,
                AVG(o.total_amount) as avg_order_value,
                SUM(o.total_amount) as total_lifetime_value,
                STDDEV(o.total_amount) as order_value_variance,
                COUNT(DISTINCT TRUNC(o.order_date)) as active_days,
                MAX(o.order_date) as last_order_date,
                MIN(o.order_date) as first_order_date,
                MONTHS_BETWEEN(SYSDATE, MAX(o.order_date)) as months_since_last_order,
                MONTHS_BETWEEN(MAX(o.order_date), MIN(o.order_date)) as customer_lifespan_months,
                COUNT(DISTINCT oi.product_id) as unique_products_purchased,
                AVG(CASE WHEN pr.rating IS NOT NULL THEN pr.rating END) as avg_product_rating
            FROM users_${environment} u
            INNER JOIN orders_${environment} o ON u.user_id = o.user_id
            INNER JOIN order_items_${environment} oi ON o.order_id = oi.order_id
            LEFT JOIN product_reviews_${environment} pr ON oi.product_id = pr.product_id AND pr.user_id = u.user_id
            LEFT JOIN user_preferences_${environment} up ON u.user_id = up.user_id
            WHERE o.order_date >= ADD_MONTHS(SYSDATE, -#{analysisMonths})
            AND o.status = 'COMPLETED'
            AND u.status = 'ACTIVE'
            AND u.account_verification_status = 'VERIFIED'
            GROUP BY u.user_id, u.user_type, u.registration_date
        ),
        product_category_preferences AS (
            SELECT 
                cbm.user_id,
                COUNT(DISTINCT c.category_id) as category_diversity,
                LISTAGG(c.category_name, ', ') WITHIN GROUP (ORDER BY category_purchase_count DESC) as top_categories,
                MAX(category_purchase_count) as max_category_purchases,
                AVG(category_purchase_amount) as avg_category_spending
            FROM customer_behavior_metrics cbm
            INNER JOIN (
                SELECT 
                    o.user_id,
                    c.category_id,
                    c.category_name,
                    COUNT(*) as category_purchase_count,
                    SUM(oi.quantity * oi.unit_price) as category_purchase_amount
                FROM orders_${environment} o
                INNER JOIN order_items_${environment} oi ON o.order_id = oi.order_id
                INNER JOIN products_${environment} p ON oi.product_id = p.product_id
                INNER JOIN categories_${environment} c ON p.category_id = c.category_id
                WHERE o.order_date >= ADD_MONTHS(SYSDATE, -#{analysisMonths})
                AND o.status = 'COMPLETED'
                GROUP BY o.user_id, c.category_id, c.category_name
            ) category_stats ON cbm.user_id = category_stats.user_id
            GROUP BY cbm.user_id
        ),
        payment_behavior_analysis AS (
            SELECT 
                cbm.user_id,
                COUNT(DISTINCT pm.payment_method) as payment_method_diversity,
                MODE() WITHIN GROUP (ORDER BY pm.payment_method) as preferred_payment_method,
                AVG(pm.processing_time_seconds) as avg_payment_processing_time,
                COUNT(CASE WHEN pm.payment_status = 'FAILED' THEN 1 END) as failed_payment_count,
                COUNT(CASE WHEN pm.requires_manual_review = 'Y' THEN 1 END) as manual_review_count
            FROM customer_behavior_metrics cbm
            INNER JOIN orders_${environment} o ON cbm.user_id = o.user_id
            INNER JOIN payments_${environment} pm ON o.order_id = pm.order_id
            WHERE pm.payment_date >= ADD_MONTHS(SYSDATE, -#{analysisMonths})
            GROUP BY cbm.user_id
        ),
        loyalty_scoring AS (
            SELECT 
                cbm.user_id,
                CASE 
                    WHEN cbm.customer_lifespan_months >= 24 AND cbm.order_frequency >= 50 THEN 100
                    WHEN cbm.customer_lifespan_months >= 12 AND cbm.order_frequency >= 20 THEN 80
                    WHEN cbm.customer_lifespan_months >= 6 AND cbm.order_frequency >= 10 THEN 60
                    WHEN cbm.months_since_last_order &lt;= 3 THEN 40
                    ELSE 20
                END as loyalty_score,
                CASE 
                    WHEN cbm.total_lifetime_value >= 2000000 THEN 100
                    WHEN cbm.total_lifetime_value >= 1000000 THEN 80
                    WHEN cbm.total_lifetime_value >= 500000 THEN 60
                    WHEN cbm.total_lifetime_value >= 100000 THEN 40
                    ELSE 20
                END as value_score,
                CASE 
                    WHEN pcp.category_diversity >= 10 THEN 100
                    WHEN pcp.category_diversity >= 5 THEN 80
                    WHEN pcp.category_diversity >= 3 THEN 60
                    ELSE 40
                END as diversity_score
            FROM customer_behavior_metrics cbm
            INNER JOIN product_category_preferences pcp ON cbm.user_id = pcp.user_id
        )
        SELECT 
            cbm.user_id,
            u.username,
            u.email,
            u.company_name,
            cbm.user_type,
            CASE 
                WHEN (ls.loyalty_score + ls.value_score + ls.diversity_score) / 3 >= 90 THEN 'CHAMPION'
                WHEN (ls.loyalty_score + ls.value_score + ls.diversity_score) / 3 >= 80 THEN 'VIP'
                WHEN (ls.loyalty_score + ls.value_score + ls.diversity_score) / 3 >= 70 THEN 'PREMIUM_LOYAL'
                WHEN (ls.loyalty_score + ls.value_score + ls.diversity_score) / 3 >= 60 THEN 'LOYAL'
                WHEN cbm.avg_order_value >= 200000 THEN 'HIGH_VALUE'
                WHEN cbm.order_frequency >= 15 THEN 'FREQUENT_BUYER'
                WHEN cbm.months_since_last_order &lt;= 3 THEN 'RECENT_ACTIVE'
                WHEN cbm.months_since_last_order &lt;= 6 THEN 'MODERATE_ACTIVE'
                WHEN cbm.months_since_last_order &lt;= 12 THEN 'LOW_ACTIVE'
                ELSE 'AT_RISK'
            END as customer_segment,
            cbm.order_frequency,
            ROUND(cbm.avg_order_value, 2) as avg_order_value,
            ROUND(cbm.total_lifetime_value, 2) as total_lifetime_value,
            cbm.customer_lifespan_months,
            cbm.months_since_last_order,
            pcp.category_diversity,
            pcp.top_categories,
            ROUND(pcp.avg_category_spending, 2) as avg_category_spending,
            pba.payment_method_diversity,
            pba.preferred_payment_method,
            ROUND(pba.avg_payment_processing_time, 2) as avg_payment_processing_time,
            pba.failed_payment_count,
            ls.loyalty_score,
            ls.value_score,
            ls.diversity_score,
            ROUND((ls.loyalty_score + ls.value_score + ls.diversity_score) / 3, 2) as overall_score,
            RANK() OVER (ORDER BY cbm.total_lifetime_value DESC) as value_rank,
            PERCENT_RANK() OVER (ORDER BY cbm.order_frequency) as frequency_percentile
        FROM customer_behavior_metrics cbm
        INNER JOIN users_${environment} u ON cbm.user_id = u.user_id
        INNER JOIN product_category_preferences pcp ON cbm.user_id = pcp.user_id
        INNER JOIN payment_behavior_analysis pba ON cbm.user_id = pba.user_id
        INNER JOIN loyalty_scoring ls ON cbm.user_id = ls.user_id
        LEFT JOIN user_business_info_${environment} ubi ON u.user_id = ubi.user_id
        WHERE cbm.total_lifetime_value >= #{minLifetimeValue}
        <if test="targetSegments != null and targetSegments.size() > 0">
            AND (ls.loyalty_score + ls.value_score + ls.diversity_score) / 3 >= #{minOverallScore}
        </if>
        <if test="includeBusinessUsers == true">
            AND ubi.business_type IS NOT NULL
        </if>
        ORDER BY cbm.total_lifetime_value DESC, cbm.order_frequency DESC
        <if test="maxResults != null">
            FETCH FIRST #{maxResults} ROWS ONLY
        </if>
    </select>

    <!-- 
    복잡한 재고 최적화 분석 - 다중 데이터센터 재고 분석
    복잡한 서브쿼리, 윈도우 함수, 통계 분석 포함
    -->
    <select id="executeInventoryOptimizationAnalysis" parameterType="map" resultType="map">
        WITH multi_datacenter_inventory AS (
            SELECT 
                p.product_id,
                p.product_name,
                p.category_id,
                c.category_name,
                SUM(i.current_quantity) as total_inventory_across_dcs,
                COUNT(DISTINCT i.datacenter_code) as datacenter_count,
                AVG(i.current_quantity) as avg_inventory_per_dc,
                STDDEV(i.current_quantity) as inventory_distribution_stddev,
                MAX(i.last_movement_date) as latest_movement_date,
                MIN(i.last_movement_date) as earliest_movement_date
            FROM products_${environment} p
            INNER JOIN categories_${environment} c ON p.category_id = c.category_id
            INNER JOIN inventory_${environment} i ON p.product_id = i.product_id
            WHERE i.datacenter_code IN 
            <foreach collection="datacenters" item="dc" open="(" separator="," close=")">
                #{dc}
            </foreach>
            AND i.status = 'ACTIVE'
            AND p.status = 'ACTIVE'
            AND i.last_updated >= ADD_MONTHS(SYSDATE, -#{inventoryAgeMonths})
            GROUP BY p.product_id, p.product_name, p.category_id, c.category_name
        ),
        sales_velocity_analysis AS (
            SELECT 
                mdi.product_id,
                COUNT(DISTINCT o.order_date) as sales_days,
                SUM(oi.quantity) as total_units_sold,
                AVG(oi.quantity) as avg_units_per_order,
                SUM(oi.quantity * oi.unit_price) as total_sales_revenue,
                COUNT(DISTINCT o.user_id) as unique_customers,
                ROUND(SUM(oi.quantity) / NULLIF(COUNT(DISTINCT o.order_date), 0), 2) as daily_sales_velocity,
                LAG(SUM(oi.quantity)) OVER (PARTITION BY mdi.product_id ORDER BY EXTRACT(MONTH FROM o.order_date)) as prev_month_sales,
                CASE 
                    WHEN LAG(SUM(oi.quantity)) OVER (PARTITION BY mdi.product_id ORDER BY EXTRACT(MONTH FROM o.order_date)) > 0
                    THEN ROUND(((SUM(oi.quantity) - LAG(SUM(oi.quantity)) OVER (PARTITION BY mdi.product_id ORDER BY EXTRACT(MONTH FROM o.order_date))) 
                               / LAG(SUM(oi.quantity)) OVER (PARTITION BY mdi.product_id ORDER BY EXTRACT(MONTH FROM o.order_date))) * 100, 2)
                    ELSE 0
                END as sales_growth_rate
            FROM multi_datacenter_inventory mdi
            INNER JOIN order_items_${environment} oi ON mdi.product_id = oi.product_id
            INNER JOIN orders_${environment} o ON oi.order_id = o.order_id
            WHERE o.order_date >= ADD_MONTHS(SYSDATE, -#{salesAnalysisMonths})
            AND o.status = 'COMPLETED'
            AND o.datacenter_code IN 
            <foreach collection="datacenters" item="dc" open="(" separator="," close=")">
                #{dc}
            </foreach>
            GROUP BY mdi.product_id, EXTRACT(MONTH FROM o.order_date)
        ),
        inventory_turnover_calculation AS (
            SELECT 
                mdi.product_id,
                mdi.total_inventory_across_dcs,
                sva.daily_sales_velocity,
                CASE 
                    WHEN sva.daily_sales_velocity > 0 
                    THEN ROUND(mdi.total_inventory_across_dcs / sva.daily_sales_velocity, 2)
                    ELSE 999
                END as days_of_inventory,
                CASE 
                    WHEN sva.daily_sales_velocity > 0 
                    THEN ROUND((sva.daily_sales_velocity * 365) / NULLIF(mdi.total_inventory_across_dcs, 0), 2)
                    ELSE 0
                END as inventory_turnover_ratio,
                sva.sales_growth_rate,
                CASE 
                    WHEN mdi.total_inventory_across_dcs > sva.daily_sales_velocity * 90 THEN 'EXCESS'
                    WHEN mdi.total_inventory_across_dcs > sva.daily_sales_velocity * 60 THEN 'HIGH'
                    WHEN mdi.total_inventory_across_dcs > sva.daily_sales_velocity * 30 THEN 'OPTIMAL'
                    WHEN mdi.total_inventory_across_dcs > sva.daily_sales_velocity * 14 THEN 'LOW'
                    ELSE 'CRITICAL'
                END as inventory_status
            FROM multi_datacenter_inventory mdi
            INNER JOIN sales_velocity_analysis sva ON mdi.product_id = sva.product_id
        ),
        cost_analysis AS (
            SELECT 
                itc.product_id,
                p.unit_cost,
                p.selling_price,
                (p.selling_price - p.unit_cost) as unit_profit,
                ROUND(((p.selling_price - p.unit_cost) / NULLIF(p.selling_price, 0)) * 100, 2) as profit_margin_percent,
                itc.total_inventory_across_dcs * p.unit_cost as total_inventory_cost,
                itc.days_of_inventory * (p.unit_cost * #{dailyStorageCostRate}) as estimated_storage_cost,
                CASE 
                    WHEN itc.inventory_status = 'EXCESS' 
                    THEN (itc.total_inventory_across_dcs - (itc.daily_sales_velocity * 60)) * p.unit_cost
                    ELSE 0
                END as excess_inventory_cost
            FROM inventory_turnover_calculation itc
            INNER JOIN products_${environment} p ON itc.product_id = p.product_id
            WHERE p.cost_updated_date >= ADD_MONTHS(SYSDATE, -3)  -- 최근 3개월 내 비용 정보
        )
        SELECT 
            mdi.product_id,
            mdi.product_name,
            mdi.category_name,
            mdi.total_inventory_across_dcs,
            mdi.datacenter_count,
            ROUND(mdi.avg_inventory_per_dc, 2) as avg_inventory_per_dc,
            ROUND(mdi.inventory_distribution_stddev, 2) as inventory_distribution_stddev,
            ROUND(sva.daily_sales_velocity, 2) as daily_sales_velocity,
            itc.days_of_inventory,
            itc.inventory_turnover_ratio,
            itc.inventory_status,
            ROUND(sva.sales_growth_rate, 2) as sales_growth_rate,
            ROUND(ca.unit_profit, 2) as unit_profit,
            ca.profit_margin_percent,
            ROUND(ca.total_inventory_cost, 2) as total_inventory_cost,
            ROUND(ca.estimated_storage_cost, 2) as estimated_storage_cost,
            ROUND(ca.excess_inventory_cost, 2) as excess_inventory_cost,
            CASE 
                WHEN itc.inventory_status = 'EXCESS' AND ca.excess_inventory_cost > #{excessCostThreshold} THEN 'CLEARANCE_RECOMMENDED'
                WHEN itc.inventory_status = 'CRITICAL' THEN 'URGENT_RESTOCK'
                WHEN itc.inventory_status = 'LOW' AND sva.sales_growth_rate > 20 THEN 'RESTOCK_RECOMMENDED'
                WHEN itc.inventory_status = 'OPTIMAL' THEN 'MAINTAIN_CURRENT'
                ELSE 'MONITOR'
            END as recommended_action,
            RANK() OVER (PARTITION BY mdi.category_id ORDER BY ca.excess_inventory_cost DESC) as excess_cost_rank_in_category,
            PERCENT_RANK() OVER (ORDER BY itc.inventory_turnover_ratio DESC) as turnover_percentile
        FROM multi_datacenter_inventory mdi
        INNER JOIN sales_velocity_analysis sva ON mdi.product_id = sva.product_id
        INNER JOIN inventory_turnover_calculation itc ON mdi.product_id = itc.product_id
        INNER JOIN cost_analysis ca ON mdi.product_id = ca.product_id
        WHERE 1=1
        <if test="categoryIds != null and categoryIds.size() > 0">
            AND mdi.category_id IN 
            <foreach collection="categoryIds" item="categoryId" open="(" separator="," close=")">
                #{categoryId}
            </foreach>
        </if>
        <if test="minInventoryValue != null">
            AND ca.total_inventory_cost >= #{minInventoryValue}
        </if>
        <if test="inventoryStatuses != null and inventoryStatuses.size() > 0">
            AND itc.inventory_status IN 
            <foreach collection="inventoryStatuses" item="status" open="(" separator="," close=")">
                #{status}
            </foreach>
        </if>
        ORDER BY ca.excess_inventory_cost DESC, itc.inventory_turnover_ratio ASC
        <if test="maxResults != null">
            FETCH FIRST #{maxResults} ROWS ONLY
        </if>
    </select>

    <!-- 
    복잡한 배치 정산 처리 - 실제 금융 시스템 수준의 복잡도
    MERGE, 복잡한 조건부 로직, 다중 테이블 처리
    -->
    <update id="executeBatchSettlementProcessing" parameterType="map">
        <!-- 1단계: 임시 정산 테이블 생성 및 데이터 준비 -->
        CREATE GLOBAL TEMPORARY TABLE temp_settlement_${batchId} AS
        SELECT 
            u.user_id,
            u.username,
            u.business_registration_number,
            SUM(CASE WHEN t.transaction_type = 'SALE' THEN t.amount ELSE 0 END) as gross_sales,
            SUM(CASE WHEN t.transaction_type = 'REFUND' THEN t.amount ELSE 0 END) as total_refunds,
            SUM(CASE WHEN t.transaction_type = 'SALE' THEN t.amount ELSE 0 END) - 
            SUM(CASE WHEN t.transaction_type = 'REFUND' THEN t.amount ELSE 0 END) as net_sales,
            COUNT(DISTINCT t.order_id) as transaction_count,
            AVG(t.amount) as avg_transaction_amount,
            MAX(t.transaction_date) as last_transaction_date,
            CASE 
                WHEN u.settlement_tier = 'PREMIUM' THEN 0.025
                WHEN u.settlement_tier = 'STANDARD' THEN 0.030
                ELSE 0.035
            END as fee_rate,
            CASE 
                WHEN EXISTS (
                    SELECT 1 FROM tax_exemptions_${environment} te 
                    WHERE te.user_id = u.user_id 
                    AND te.exemption_type IN ('CORPORATE', 'NON_PROFIT')
                    AND te.valid_until >= SYSDATE
                ) THEN 0
                WHEN u.business_type = 'INDIVIDUAL' THEN 0.033  -- 개인사업자 3.3%
                WHEN u.business_type = 'CORPORATE' THEN 0.10    -- 법인 10%
                ELSE 0.10
            END as tax_rate
        FROM users_${environment} u
        INNER JOIN transactions_${environment}_${settlementYear} t ON u.user_id = t.user_id
        INNER JOIN orders_${environment} o ON t.order_id = o.order_id
        LEFT JOIN user_business_info_${environment} ubi ON u.user_id = ubi.user_id
        WHERE t.transaction_date BETWEEN TO_DATE(#{settlementDateFrom}, 'YYYY-MM-DD') 
                                    AND TO_DATE(#{settlementDateTo}, 'YYYY-MM-DD')
        AND t.settlement_status = 'PENDING'
        AND u.settlement_account_status = 'VERIFIED'
        AND o.fraud_check_status = 'PASSED'
        GROUP BY u.user_id, u.username, u.business_registration_number, u.settlement_tier, u.business_type
        HAVING SUM(CASE WHEN t.transaction_type = 'SALE' THEN t.amount ELSE 0 END) >= #{minSettlementAmount};

        <!-- 2단계: 정산 금액 계산 및 MERGE 처리 -->
        MERGE INTO user_settlements_${environment} us
        USING (
            SELECT 
                ts.user_id,
                ts.gross_sales,
                ts.total_refunds,
                ts.net_sales,
                ts.transaction_count,
                ROUND(ts.net_sales * ts.fee_rate, 2) as platform_fee,
                ROUND(ts.net_sales * ts.tax_rate, 2) as tax_amount,
                ROUND(ts.net_sales - (ts.net_sales * ts.fee_rate) - (ts.net_sales * ts.tax_rate), 2) as final_settlement_amount,
                TO_DATE(#{settlementDateFrom}, 'YYYY-MM-DD') as settlement_period_start,
                TO_DATE(#{settlementDateTo}, 'YYYY-MM-DD') as settlement_period_end,
                #{batchId} as batch_id,
                SYSDATE as calculated_date
            FROM temp_settlement_${batchId} ts
            WHERE ts.net_sales > 0
        ) settlement_data ON (
            us.user_id = settlement_data.user_id 
            AND us.settlement_period_start = settlement_data.settlement_period_start
            AND us.settlement_period_end = settlement_data.settlement_period_end
        )
        WHEN MATCHED THEN
            UPDATE SET 
                us.gross_sales = settlement_data.gross_sales,
                us.total_refunds = settlement_data.total_refunds,
                us.net_sales = settlement_data.net_sales,
                us.transaction_count = settlement_data.transaction_count,
                us.platform_fee = settlement_data.platform_fee,
                us.tax_amount = settlement_data.tax_amount,
                us.final_settlement_amount = settlement_data.final_settlement_amount,
                us.recalculated_date = SYSDATE,
                us.batch_id = settlement_data.batch_id,
                us.status = 'RECALCULATED'
        WHEN NOT MATCHED THEN
            INSERT (
                settlement_id, user_id, settlement_period_start, settlement_period_end,
                gross_sales, total_refunds, net_sales, transaction_count,
                platform_fee, tax_amount, final_settlement_amount,
                status, batch_id, created_date, updated_date
            ) VALUES (
                'SETT_' || TO_CHAR(SYSDATE, 'YYYYMMDD') || '_' || settlement_data.user_id,
                settlement_data.user_id,
                settlement_data.settlement_period_start,
                settlement_data.settlement_period_end,
                settlement_data.gross_sales,
                settlement_data.total_refunds,
                settlement_data.net_sales,
                settlement_data.transaction_count,
                settlement_data.platform_fee,
                settlement_data.tax_amount,
                settlement_data.final_settlement_amount,
                'CALCULATED',
                settlement_data.batch_id,
                SYSDATE,
                SYSDATE
            );

        <!-- 3단계: 트랜잭션 상태 업데이트 -->
        UPDATE transactions_${environment}_${settlementYear} t
        SET t.settlement_status = 'PROCESSED',
            t.settlement_batch_id = #{batchId},
            t.settlement_processed_date = SYSDATE
        WHERE t.user_id IN (
            SELECT DISTINCT user_id FROM temp_settlement_${batchId}
        )
        AND t.transaction_date BETWEEN TO_DATE(#{settlementDateFrom}, 'YYYY-MM-DD') 
                                  AND TO_DATE(#{settlementDateTo}, 'YYYY-MM-DD')
        AND t.settlement_status = 'PENDING';

        <!-- 4단계: 정산 통계 업데이트 -->
        MERGE INTO settlement_statistics_${environment} ss
        USING (
            SELECT 
                TO_DATE(#{settlementDateFrom}, 'YYYY-MM-DD') as stat_date,
                COUNT(DISTINCT user_id) as settled_user_count,
                SUM(final_settlement_amount) as total_settlement_amount,
                AVG(final_settlement_amount) as avg_settlement_amount,
                SUM(platform_fee) as total_platform_fee,
                SUM(tax_amount) as total_tax_amount,
                #{batchId} as batch_id
            FROM user_settlements_${environment}
            WHERE batch_id = #{batchId}
        ) batch_stats ON (ss.stat_date = batch_stats.stat_date)
        WHEN MATCHED THEN
            UPDATE SET 
                ss.settled_user_count = ss.settled_user_count + batch_stats.settled_user_count,
                ss.total_settlement_amount = ss.total_settlement_amount + batch_stats.total_settlement_amount,
                ss.total_platform_fee = ss.total_platform_fee + batch_stats.total_platform_fee,
                ss.total_tax_amount = ss.total_tax_amount + batch_stats.total_tax_amount,
                ss.last_batch_id = batch_stats.batch_id,
                ss.updated_date = SYSDATE
        WHEN NOT MATCHED THEN
            INSERT (
                stat_id, stat_date, settled_user_count, total_settlement_amount,
                avg_settlement_amount, total_platform_fee, total_tax_amount,
                last_batch_id, created_date, updated_date
            ) VALUES (
                'STAT_' || TO_CHAR(batch_stats.stat_date, 'YYYYMMDD'),
                batch_stats.stat_date,
                batch_stats.settled_user_count,
                batch_stats.total_settlement_amount,
                batch_stats.avg_settlement_amount,
                batch_stats.total_platform_fee,
                batch_stats.total_tax_amount,
                batch_stats.batch_id,
                SYSDATE,
                SYSDATE
            );

        <!-- 5단계: 임시 테이블 정리 -->
        DROP TABLE temp_settlement_${batchId}
    </update>

    <!-- 
    복잡한 실시간 대시보드 쿼리 - 실시간 KPI 계산
    다중 서브쿼리, 윈도우 함수, 실시간 집계
    -->
    <select id="executeRealTimeDashboardMetrics" parameterType="map" resultType="map">
        WITH real_time_metrics AS (
            SELECT 
                -- 실시간 주문 지표
                (SELECT COUNT(*) 
                 FROM orders_${environment} 
                 WHERE order_date >= TRUNC(SYSDATE) 
                 AND status = 'COMPLETED') as today_completed_orders,
                
                (SELECT COUNT(*) 
                 FROM orders_${environment} 
                 WHERE order_date >= SYSDATE - INTERVAL '1' HOUR 
                 AND status = 'COMPLETED') as last_hour_completed_orders,
                
                (SELECT SUM(total_amount) 
                 FROM orders_${environment} 
                 WHERE order_date >= TRUNC(SYSDATE) 
                 AND status = 'COMPLETED') as today_revenue,
                
                (SELECT SUM(total_amount) 
                 FROM orders_${environment} 
                 WHERE order_date >= SYSDATE - INTERVAL '1' HOUR 
                 AND status = 'COMPLETED') as last_hour_revenue,
                
                -- 실시간 사용자 지표
                (SELECT COUNT(DISTINCT user_id) 
                 FROM user_sessions_${environment} 
                 WHERE session_start >= TRUNC(SYSDATE) 
                 AND session_status = 'ACTIVE') as today_active_users,
                
                (SELECT COUNT(DISTINCT user_id) 
                 FROM user_sessions_${environment} 
                 WHERE session_start >= SYSDATE - INTERVAL '1' HOUR) as last_hour_new_sessions,
                
                -- 실시간 재고 지표
                (SELECT COUNT(*) 
                 FROM products_${environment} p
                 INNER JOIN inventory_${environment} i ON p.product_id = i.product_id
                 WHERE i.current_quantity &lt;= p.min_stock_level 
                 AND p.status = 'ACTIVE') as low_stock_products,
                
                (SELECT COUNT(*) 
                 FROM products_${environment} p
                 INNER JOIN inventory_${environment} i ON p.product_id = i.product_id
                 WHERE i.current_quantity = 0 
                 AND p.status = 'ACTIVE') as out_of_stock_products,
                
                -- 실시간 결제 지표
                (SELECT COUNT(*) 
                 FROM payments_${environment} 
                 WHERE payment_date >= SYSDATE - INTERVAL '1' HOUR 
                 AND payment_status = 'FAILED') as last_hour_failed_payments,
                
                (SELECT AVG(processing_time_seconds) 
                 FROM payments_${environment} 
                 WHERE payment_date >= SYSDATE - INTERVAL '1' HOUR 
                 AND payment_status = 'COMPLETED') as avg_payment_processing_time
            FROM dual
        ),
        trend_analysis AS (
            SELECT 
                -- 시간대별 트렌드 (지난 24시간)
                EXTRACT(HOUR FROM o.order_date) as order_hour,
                COUNT(*) as hourly_order_count,
                SUM(o.total_amount) as hourly_revenue,
                AVG(o.total_amount) as avg_hourly_order_value,
                COUNT(DISTINCT o.user_id) as unique_hourly_customers,
                LAG(COUNT(*)) OVER (ORDER BY EXTRACT(HOUR FROM o.order_date)) as prev_hour_orders,
                CASE 
                    WHEN LAG(COUNT(*)) OVER (ORDER BY EXTRACT(HOUR FROM o.order_date)) > 0
                    THEN ROUND(((COUNT(*) - LAG(COUNT(*)) OVER (ORDER BY EXTRACT(HOUR FROM o.order_date))) 
                               / LAG(COUNT(*)) OVER (ORDER BY EXTRACT(HOUR FROM o.order_date))) * 100, 2)
                    ELSE 0
                END as hourly_growth_rate
            FROM orders_${environment} o
            WHERE o.order_date >= SYSDATE - INTERVAL '24' HOUR
            AND o.status = 'COMPLETED'
            GROUP BY EXTRACT(HOUR FROM o.order_date)
        ),
        performance_alerts AS (
            SELECT 
                'REVENUE' as metric_type,
                CASE 
                    WHEN rm.today_revenue < #{revenueThreshold} * 0.8 THEN 'CRITICAL'
                    WHEN rm.today_revenue < #{revenueThreshold} * 0.9 THEN 'WARNING'
                    ELSE 'NORMAL'
                END as alert_level,
                rm.today_revenue as current_value,
                #{revenueThreshold} as target_value
            FROM real_time_metrics rm
            UNION ALL
            SELECT 
                'ACTIVE_USERS' as metric_type,
                CASE 
                    WHEN rm.today_active_users < #{activeUserThreshold} * 0.8 THEN 'CRITICAL'
                    WHEN rm.today_active_users < #{activeUserThreshold} * 0.9 THEN 'WARNING'
                    ELSE 'NORMAL'
                END as alert_level,
                rm.today_active_users as current_value,
                #{activeUserThreshold} as target_value
            FROM real_time_metrics rm
            UNION ALL
            SELECT 
                'PAYMENT_FAILURES' as metric_type,
                CASE 
                    WHEN rm.last_hour_failed_payments > #{maxFailedPayments} THEN 'CRITICAL'
                    WHEN rm.last_hour_failed_payments > #{maxFailedPayments} * 0.7 THEN 'WARNING'
                    ELSE 'NORMAL'
                END as alert_level,
                rm.last_hour_failed_payments as current_value,
                #{maxFailedPayments} as target_value
            FROM real_time_metrics rm
        )
        SELECT 
            SYSDATE as dashboard_timestamp,
            rm.today_completed_orders,
            rm.last_hour_completed_orders,
            ROUND(rm.today_revenue, 2) as today_revenue,
            ROUND(rm.last_hour_revenue, 2) as last_hour_revenue,
            rm.today_active_users,
            rm.last_hour_new_sessions,
            rm.low_stock_products,
            rm.out_of_stock_products,
            rm.last_hour_failed_payments,
            ROUND(rm.avg_payment_processing_time, 2) as avg_payment_processing_time,
            
            -- 트렌드 지표
            (SELECT MAX(hourly_growth_rate) FROM trend_analysis WHERE hourly_growth_rate IS NOT NULL) as max_hourly_growth,
            (SELECT MIN(hourly_growth_rate) FROM trend_analysis WHERE hourly_growth_rate IS NOT NULL) as min_hourly_growth,
            (SELECT AVG(hourly_order_count) FROM trend_analysis) as avg_hourly_orders,
            
            -- 알림 지표
            (SELECT COUNT(*) FROM performance_alerts WHERE alert_level = 'CRITICAL') as critical_alerts,
            (SELECT COUNT(*) FROM performance_alerts WHERE alert_level = 'WARNING') as warning_alerts,
            
            -- 비교 지표 (어제 같은 시간대 대비)
            CASE 
                WHEN (SELECT SUM(total_amount) FROM orders_${environment} 
                      WHERE order_date BETWEEN TRUNC(SYSDATE-1) AND TRUNC(SYSDATE-1) + INTERVAL '1' DAY - INTERVAL '1' SECOND
                      AND status = 'COMPLETED') > 0
                THEN ROUND(((rm.today_revenue - (SELECT SUM(total_amount) FROM orders_${environment} 
                                               WHERE order_date BETWEEN TRUNC(SYSDATE-1) AND TRUNC(SYSDATE-1) + INTERVAL '1' DAY - INTERVAL '1' SECOND
                                               AND status = 'COMPLETED')) 
                           / (SELECT SUM(total_amount) FROM orders_${environment} 
                              WHERE order_date BETWEEN TRUNC(SYSDATE-1) AND TRUNC(SYSDATE-1) + INTERVAL '1' DAY - INTERVAL '1' SECOND
                              AND status = 'COMPLETED')) * 100, 2)
                ELSE 0
            END as revenue_growth_vs_yesterday,
            
            #{environment} as environment,
            #{batchId} as batch_id
        FROM real_time_metrics rm
    </select>

    <!-- 
    복잡한 데이터 마이그레이션 쿼리 - 환경 간 데이터 이관
    복잡한 데이터 변환, 검증, 매핑 로직 포함
    -->
    <insert id="executeCrossEnvironmentDataMigration" parameterType="map">
        <!-- 1단계: 소스 환경에서 데이터 추출 및 변환 -->
        INSERT INTO migration_staging_${targetEnvironment} (
            staging_id, source_user_id, target_user_id, 
            source_data, transformed_data, validation_status,
            migration_batch_id, created_date
        )
        SELECT 
            'MIG_' || TO_CHAR(SYSDATE, 'YYYYMMDDHH24MISS') || '_' || ROWNUM as staging_id,
            su.user_id as source_user_id,
            CASE 
                WHEN tu.user_id IS NOT NULL THEN tu.user_id
                ELSE 'NEW_' || su.user_id || '_' || #{targetEnvironment}
            END as target_user_id,
            
            -- 소스 데이터 JSON 형태로 저장
            JSON_OBJECT(
                'user_id' VALUE su.user_id,
                'username' VALUE su.username,
                'email' VALUE su.email,
                'profile' VALUE JSON_OBJECT(
                    'full_name' VALUE sp.full_name,
                    'phone' VALUE sp.phone,
                    'address' VALUE sp.address
                ),
                'orders' VALUE (
                    SELECT JSON_ARRAYAGG(
                        JSON_OBJECT(
                            'order_id' VALUE so.order_id,
                            'order_date' VALUE so.order_date,
                            'total_amount' VALUE so.total_amount,
                            'items' VALUE (
                                SELECT JSON_ARRAYAGG(
                                    JSON_OBJECT(
                                        'product_id' VALUE soi.product_id,
                                        'quantity' VALUE soi.quantity,
                                        'unit_price' VALUE soi.unit_price
                                    )
                                )
                                FROM order_items_${sourceEnvironment} soi
                                WHERE soi.order_id = so.order_id
                            )
                        )
                    )
                    FROM orders_${sourceEnvironment} so
                    WHERE so.user_id = su.user_id
                    AND so.order_date >= ADD_MONTHS(SYSDATE, -#{migrationMonths})
                )
            ) as source_data,
            
            -- 변환된 데이터
            JSON_OBJECT(
                'target_username' VALUE CASE 
                    WHEN tu.user_id IS NOT NULL THEN tu.username
                    ELSE LOWER(su.username) || '_migrated'
                END,
                'target_email' VALUE CASE 
                    WHEN tu.user_id IS NOT NULL THEN tu.email
                    ELSE su.email
                END,
                'migration_notes' VALUE CASE 
                    WHEN tu.user_id IS NOT NULL THEN 'EXISTING_USER_UPDATE'
                    ELSE 'NEW_USER_CREATION'
                END
            ) as transformed_data,
            
            -- 검증 상태
            CASE 
                WHEN su.email IS NULL OR su.username IS NULL THEN 'VALIDATION_FAILED'
                WHEN tu.user_id IS NOT NULL AND tu.email != su.email THEN 'EMAIL_CONFLICT'
                WHEN (SELECT COUNT(*) FROM orders_${sourceEnvironment} WHERE user_id = su.user_id) = 0 THEN 'NO_ORDERS'
                ELSE 'VALIDATION_PASSED'
            END as validation_status,
            
            #{migrationBatchId} as migration_batch_id,
            SYSDATE as created_date
            
        FROM users_${sourceEnvironment} su
        LEFT JOIN user_profiles_${sourceEnvironment} sp ON su.user_id = sp.user_id
        LEFT JOIN users_${targetEnvironment} tu ON su.email = tu.email  -- 이메일로 기존 사용자 매칭
        WHERE su.status = 'ACTIVE'
        AND su.created_date >= ADD_MONTHS(SYSDATE, -#{migrationMonths})
        <if test="userTypes != null and userTypes.size() > 0">
            AND su.user_type IN 
            <foreach collection="userTypes" item="userType" open="(" separator="," close=")">
                #{userType}
            </foreach>
        </if>
        <if test="excludeTestUsers == true">
            AND su.username NOT LIKE '%test%'
            AND su.email NOT LIKE '%test%'
        </if>
    </insert>

</mapper>
